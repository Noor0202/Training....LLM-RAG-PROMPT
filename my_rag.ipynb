{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community\n",
        "!pip install pypdf\n",
        "!pip install langchain_google_genai\n",
        "!pip install chromadb\n",
        "!pip install langchain\n",
        "!pip install -U langchain-huggingface"
      ],
      "metadata": {
        "id": "JY-ET6hWY4-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "Jsi4z1Mbg7L0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize embedding function using HuggingFace\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embedding_function = HuggingFaceEmbeddings(model_name=model_name)"
      ],
      "metadata": {
        "id": "3zXRPwWqmjSA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Flan-T5 pipeline for text generation\n",
        "def initialize_flan_t5():\n",
        "    try:\n",
        "        generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
        "        print(\"Flan-T5 model initialized successfully!\")\n",
        "        return generator\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Flan-T5: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "2YpQKby2nr_x"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load PDF and extract text (This will only be called once)\n",
        "def load_pdf(file_path):\n",
        "    try:\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        pages = loader.load_and_split()\n",
        "        documents = pages[0].page_content + pages[1].page_content\n",
        "        print(\"PDF loaded successfully!\")\n",
        "        return documents\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# 2. Split text into smaller chunks (This will only be called once)\n",
        "def split_text(documents, chunk_size=100, chunk_overlap=20):\n",
        "    try:\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap,\n",
        "            length_function=len,\n",
        "        )\n",
        "        texts = text_splitter.create_documents([documents])\n",
        "        print(\"Text split successfully!\")\n",
        "        return texts\n",
        "    except Exception as e:\n",
        "        print(f\"Error splitting text: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# 3. Create a vector store for documents\n",
        "def create_vectorstore(texts):\n",
        "    try:\n",
        "        vectorstore = Chroma.from_documents(\n",
        "            documents=texts,\n",
        "            embedding=embedding_function\n",
        "        )\n",
        "        print(\"Vectorstore created successfully!\")\n",
        "        return vectorstore\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating vectorstore: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "tEBWV4W7nxHz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Retrieve relevant documents for a query\n",
        "def retrieve_documents(vectorstore, query, k=1):\n",
        "    try:\n",
        "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
        "        retrieved_docs = retriever.get_relevant_documents(query)\n",
        "        print(\"Documents retrieved successfully!\")\n",
        "        return retrieved_docs\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving documents: {str(e)}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "qatPjl02n5C9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Generate a response using Flan-T5\n",
        "def generate_response_flan(retrieved_docs, query, generator):\n",
        "    try:\n",
        "        context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
        "        prompt = f\"Based on the following context:\\n{context}\\nAnswer the query: {query}\"\n",
        "        answer = generator(prompt, max_length=500)\n",
        "        return answer[0][\"generated_text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response with Flan-T5: {str(e)}\")\n",
        "        return \"Error generating response\""
      ],
      "metadata": {
        "id": "OrgTyD7Vn7EG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Initialize the environment\n",
        "def initialize_environment(file_path, chunk_size=100, chunk_overlap=20):\n",
        "    documents = load_pdf(file_path)\n",
        "    if not documents:\n",
        "        return None, None\n",
        "\n",
        "    texts = split_text(documents, chunk_size, chunk_overlap)\n",
        "    if not texts:\n",
        "        return None, None\n",
        "\n",
        "    vectorstore = create_vectorstore(texts)\n",
        "    if not vectorstore:\n",
        "        return None, None\n",
        "\n",
        "    return vectorstore, texts"
      ],
      "metadata": {
        "id": "1HaJJhH_n8_8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Query function\n",
        "def run_query_flan(vectorstore, query, generator, k=1):\n",
        "    retrieved_docs = retrieve_documents(vectorstore, query, k)\n",
        "    if not retrieved_docs:\n",
        "        print(\"No documents retrieved.\")\n",
        "        return\n",
        "\n",
        "    answer = generate_response_flan(retrieved_docs, query, generator)\n",
        "    print(\"Answer:\")\n",
        "    print(answer)"
      ],
      "metadata": {
        "id": "nAYkz9dsn_WV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "file_path = \"/content/Resume.pdf\"\n",
        "vectorstore, texts = initialize_environment(file_path)\n",
        "generator = initialize_flan_t5()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da_g9ieooBKL",
        "outputId": "3aad5e9a-f99a-4f77-e12f-2d4baa501105"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF loaded successfully!\n",
            "Text split successfully!\n",
            "Vectorstore created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flan-T5 model initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if vectorstore and generator:\n",
        "    query_1 = \"Tell me about Shahnoor's experience mentioned in the resume\"\n",
        "    run_query_flan(vectorstore, query_1, generator)\n",
        "\n",
        "    query_2 = \"What are Shahnoor's skills, Mention all Tech Skills?\"\n",
        "    run_query_flan(vectorstore, query_2, generator)\n",
        "\n",
        "    query_3 = \"What is the relationship between Shahnoor and Toufiq\"\n",
        "    run_query_flan(vectorstore, query_3, generator)\n",
        "\n",
        "else:\n",
        "    print(\"Failed to initialize the environment or model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WooOu70FoDom",
        "outputId": "89001206-005e-4d5f-ebe9-038dfb4ca292"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents retrieved successfully!\n",
            "Answer:\n",
            "Jr. Software Engineer\n",
            "Documents retrieved successfully!\n",
            "Answer:\n",
            "Jr. Software Engineer\n",
            "Documents retrieved successfully!\n",
            "Answer:\n",
            "brother\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RPunx3kJoTLb"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}